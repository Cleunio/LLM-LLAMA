# -*- coding: utf-8 -*-
"""Chain.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LHhjPYxbDAohIl6OV0c0KHi8VHvRif1W
"""

model_id = "meta-llama/Meta-Llama-3-8B-Instruct"

from langchain_core.prompts import ChatPromptTemplate
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant that answers general questions")
    ("user", "Explain...")
])

prompt.invoke({"topic":"AI"})

chain = prompt | llm

resp = chain.invoke({"topic":"AI", "length": "1 sentence"})

topic = "IA"  # @param {type:"string"}
length = "1 sentence" # @param {type:"string"}

resp = chain.invoke({"topic": topic, "length": length})
resp

from langchain_core.output_parsers import StrOutputParser
chain_str = chain | StrOutputParser()

chain_str.invoke({"topic": topic, "length": length})

"""Ruunable"""

from langchain_core.output.runnables import RunnableLambda
count = RunnableLambda(lambda x: f: "Words: " {len(x.split)}\n{x})

chain1 = prompt | llm | StrOutputParser() | count
chain.invoke({"topic": "AI", "lenght": "1 sentence"})